---
title: "Project"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Project}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This page contains a general overview of the project, core research questions, and the methods we used to achieve our research goals.

## Motivation

Kenny and Niels are both interested in how mathematical models can help us understand psychological constructs. In this endeavor, they have both used these mathematical models to help understand the psychometric properties of the measurements of generalization and emotion, finding sufficient reliability in the estimated parameters from their models (Vanhasbroeck et al., 2024; Yu et al., 2025). However, in this project, they wish to dig deeper into what this reliability means and whether it can signal misspecification of our models.

In the original structure of this project, Kenny focused on compensatory mechanisms while Niels focused on test-retest reliability, mimicking our expertise. In later iterations of the project, however, both analysis types intertwined.



## Research questions

(a) How do model parameters "compensate" when fitting a wrong model to data? 
(b) Can reliability degradation of the estimated parameters serve as a diagnostic tool for model misspecification?



## Study design 

### Procedure

The simulation mimics an experiment in which participants are presented with a series of quantitative stimuli and have to provide a response to this. In our analyses, the quantitative stimuli serve as the independent variable(s) while the participants' responses serve as the dependent variable. Importantly, the same string of stimuli is repeated multiple times throughout the study, allowing us to compute test-retest reliablity (see Vanhasbroeck et al., 2024).

At each step in the simulation, we generate data for a given set of participants from a _generative model_ and then estimate the parameters of another _estimation model_. These parameter sets are then subjected to analysis, computing several statistics targeting compensatory mechanisms (e.g., bias and standard errors) or parameter reliability (e.g., intra-class correlation coefficient). Importantly, all parameters are estimated on an individual-specific level.

Throughout the simulation, we vary the number of participants (25, 100, 500), number of repetitions of the same stimuli (2, 3, 4, 5), and the number of stimuli per repetition (15, 25, 50, 100). Each simulation condition is repeated 1000 times, allowing us a fine-grained look at the relevant statistics. Parameters of the models were drawn from uniform distributions with bounds $[-10, 10]$ for the intercepts and $[-5, 5]$ for the slopes.

### Models

At each step in the simulation, we compare the parametric performance of one model (the _estimation model_) when it is fit to data that were generated by another model (the _generative model_). When the estimation model and the generative model are different, then we speak of misspecification, which is of primary interest in our study. 

The models we use in our study are the following:

\begin{equation}
\begin{array}{ll}
    \text{Linear:} & y_t = \beta_0 + \beta_1 x_t \\
    \text{Quadratic:} & y_t = \beta_0 + \beta_1 x_t + \beta_2 x_t^2 \\
    \text{Cubic:} & y_t = \beta_0 + \beta_1 x_t + \beta_2 x_t^2 + \beta_3 x^3 \\
    \text{Main effects:} & y_t = \beta_0 + \beta_1 x_t + \beta_2 z_t \\
    \text{Interaction effects:} & y_t = \beta_0 + \beta_1 x_t + \beta_2 z_t + \beta_3 x_t z_t \\
\end{array}
\end{equation}
The models have been selected based on their use in the literature, where the linear, quadratic, and cubic model are often used when investigate the shape of the relation between a dependent and independent variable, while the main and interaction effect models are often used in statistical analyses.

Comparisons of the models are done in theoretically interesting ways. Specifically, we compare nested and nonnested models, allowing us a nontrivial look into compensatory mechanisms. The following nested models are compared to each other:

- Linear - Quadratic
- Quadratic - Cubic
- Main effects - Interaction effects

Additionally, we compared the following nonnested models to each other:

- TO DO: CHOOSE MODELS + CHOOSE HOW TO COMPUTE SNR ETC.

Note that each of these models can serve as the generative model and as the estimation model, allowing us to look at the effect of under- and over-parametrization.

### Analysis

#### Compensatory mechanisms

First, we compute the directed and undirected bias, which we compute as:

\begin{equation}
\begin{array}{l}
    \text{B}_\text{directed} = \frac{1}{n} \sum_{i = 1}^n (\theta_\text{estimated} - \theta_\text{generative}) \\
    \text{B}_\text{undirected} = \frac{1}{n} \sum_{i = 1}^n |\theta_\text{estimated} - \theta_\text{generative}|
\end{array}
\end{equation}
where $\theta$ represents a parameter of the generative and estimation models.

Second, we compute the relative bias, which examines the size of the bias relative to the total variation. In our study, this is computed as:

\begin{equation}
    \text{RB} = \frac{\sum_{i = 1}^n (\theta_\text{estimated} - \theta_\text{generative})}{\theta_\text{generative}}
\end{equation}

Third, we compute the mean squared error as a measure of the accuracy of the estimates, defining it as:

\begin{equation}
    \text{MSE} = \frac{1}{n} \sum_{i = 1}^n (\theta_\text{estimated} - \theta_\text{generative})^2
\end{equation}

Finally, we compute the coverage rate for each parameter. For this, we make use of the estimated value of the standard error for a parameter to construct the 95%CI around the estimated value of the parameter under the assumption of normality, specifically (NOTE: THE HIGHER SE, THE MORE LIKELY TO COVER. MAYBE WE NEED TO LOOK AT SE ITSELF AS WELL?):

\begin{equation}
    95\%CI = [\theta_\text{estimated} - 1.96 \times \text{SE}, \theta_\text{estimated} + 1.96 \times \text{SE}]
\end{equation}
where SE denotes the standard error and 1.96 represents the critical values of the normal distribution. Coverage is then indicated by checking whether $\theta_\text{generative}$ lies inside of this CI or not. Aggregating across different parameter sets, we then get to a coverage percentage, which is of interest here.

#### Reliability

First, we compute the intra-class correlation coefficient ICC(A, 1), checking how well the values of the parameters match up across different repetitions of the same strings. This serves as a measure of test-retest reliability. In our study, it is defined as:

\begin{equation}
    \text{ICC(A, 1)} = \frac{\sigma_\text{participant}^2}{\sigma_\text{total}^2}
\end{equation}
where $\sigma_\text{participant}^2$ is the variance in the parameter that can be attributed to the participants (i.e., individual differences) while $\sigma_\text{total}^2$ is the total observed variance in the parameter.

Second, we compute the coefficient of variation, which relates the observed variation in the parameter's value to the value of that parameter. In symbols:

\begin{equation}
    \text{CV} = \frac{\sigma}{| \mu |}
\end{equation}
where $\sigma$ and $\mu$ are the standard deviation and mean of the estimated parameter respectively.

Finally, we compute the signal-to-noise ratio, which is defined as:

\begin{equation}
    \text{SNR} = \frac{E[S^2]}{E[N^2]}
\end{equation}
where $S$ and $N$ represent the signal and the noise respectively. In our case, the two components can be computed as:

\begin{equation}
\begin{array}{l}
    E[S^2] = \frac{1}{n} \sum_{i = 1}^n \theta_\text{generative}^2 \\
    E[N^2] = \frac{1}{n} \sum_{i = 1}^n (\theta_\text{generative} - \theta_\text{estimated})^2
\end{array}
\end{equation}
where $\theta$ represents a parameter of the models.




## References

Vanhasbroeck, N., Vanbelle, S., Moors, A., Vanpaemel, W., & Tuerlinckx, F. (2024). Chasing consistency: On the measurement error in self-reported affect in experiments. _Behavior Research Methods, 56_(4), 3009-3022. doi: <a href="https://www.doi.org/10.3758/s13428-023-02290-3">10.3758/s13428-023-02290-3</a>

Yu, K., Lin, T.-Y., Zaman, J., Tuerlinckx, F., & Vanhasbroeck, N. (2025). Consistency of perceptual response variability in size estimation and reproduction tasks. _Behavior Research Methods, 57_, Article 127. doi: <a href="https://www.doi.org/10.3758/s13428-025-02650-1">10.3758/s13428-025-02650-1</a>