# Project

This page contains a general overview of the project, core research
questions, and the methods we used to achieve our research goals.

## Motivation

Kenny and Niels are both interested in how mathematical models can help
us understand psychological constructs. In this endeavor, they have both
used these mathematical models to help understand the psychometric
properties of the measurements of generalization and emotion, finding
sufficient reliability in the estimated parameters from their models
(Vanhasbroeck et al., 2024; Yu et al., 2025). However, in this project,
they wish to dig deeper into what this reliability means and whether it
can signal misspecification of our models.

In the original structure of this project, Kenny focused on compensatory
mechanisms while Niels focused on test-retest reliability, mimicking our
expertise. In later iterations of the project, however, both analysis
types intertwined.

## Research questions

1.  How do model parameters “compensate” when fitting a wrong model to
    data?
2.  Can reliability degradation of the estimated parameters serve as a
    diagnostic tool for model misspecification?

## Study design

### Procedure

The simulation mimics an experiment in which participants are presented
with a series of quantitative stimuli and have to provide a response to
this. In our analyses, the quantitative stimuli serve as the independent
variable(s) while the participants’ responses serve as the dependent
variable. Importantly, the same string of stimuli is repeated multiple
times throughout the study, allowing us to compute test-retest
reliablity (see Vanhasbroeck et al., 2024).

At each step in the simulation, we generate data for a given set of
participants from a *generative model* and then estimate the parameters
of another *estimation model*. These parameter sets are then subjected
to analysis, computing several statistics targeting compensatory
mechanisms (e.g., bias and standard errors) or parameter reliability
(e.g., intra-class correlation coefficient). Importantly, all parameters
are estimated on an individual-specific level.

Throughout the simulation, we vary the number of participants (25, 100,
500), number of repetitions of the same stimuli (2, 3, 4, 5), and the
number of stimuli per repetition (15, 25, 50, 100). Each simulation
condition is repeated 1000 times, allowing us a fine-grained look at the
relevant statistics. Parameters of the models were drawn from uniform
distributions with bounds $\lbrack - 10,10\rbrack$ for the intercepts
and $\lbrack - 5,5\rbrack$ for the slopes.

### Models

At each step in the simulation, we compare the parametric performance of
one model (the *estimation model*) when it is fit to data that were
generated by another model (the *generative model*). When the estimation
model and the generative model are different, then we speak of
misspecification, which is of primary interest in our study.

The models we use in our study are the following:

$$\begin{array}{ll}
\text{Linear:} & {y_{t} = \beta_{0} + \beta_{1}x_{t}} \\
\text{Quadratic:} & {y_{t} = \beta_{0} + \beta_{1}x_{t} + \beta_{2}x_{t}^{2}} \\
\text{Cubic:} & {y_{t} = \beta_{0} + \beta_{1}x_{t} + \beta_{2}x_{t}^{2} + \beta_{3}x^{3}} \\
\text{Main effects:} & {y_{t} = \beta_{0} + \beta_{1}x_{t} + \beta_{2}z_{t}} \\
\text{Interaction effects:} & {y_{t} = \beta_{0} + \beta_{1}x_{t} + \beta_{2}z_{t} + \beta_{3}x_{t}z_{t}} \\
 & 
\end{array}$$ The models have been selected based on their use in the
literature, where the linear, quadratic, and cubic model are often used
when investigate the shape of the relation between a dependent and
independent variable, while the main and interaction effect models are
often used in statistical analyses.

Comparisons of the models are done in theoretically interesting ways.
Specifically, we compare nested and nonnested models, allowing us a
nontrivial look into compensatory mechanisms. The following nested
models are compared to each other:

- Linear - Quadratic
- Quadratic - Cubic
- Main effects - Interaction effects

Additionally, we compared the following nonnested models to each other:

- TO DO: CHOOSE MODELS + CHOOSE HOW TO COMPUTE SNR ETC.

Note that each of these models can serve as the generative model and as
the estimation model, allowing us to look at the effect of under- and
over-parametrization.

### Analysis

#### Compensatory mechanisms

First, we compute the directed and undirected bias, which we compute as:

$$\begin{array}{l}
{\text{B}_{\text{directed}} = \frac{1}{n}\sum\limits_{i = 1}^{n}\left( \theta_{\text{estimated}} - \theta_{\text{generative}} \right)} \\
{\text{B}_{\text{undirected}} = \frac{1}{n}\sum\limits_{i = 1}^{n}\left| \theta_{\text{estimated}} - \theta_{\text{generative}} \right|}
\end{array}$$ where $\theta$ represents a parameter of the generative
and estimation models.

Second, we compute the relative bias, which examines the size of the
bias relative to the total variation. In our study, this is computed as:

$$\text{RB} = \frac{\sum\limits_{i = 1}^{n}\left( \theta_{\text{estimated}} - \theta_{\text{generative}} \right)}{\theta_{\text{generative}}}$$

Third, we compute the mean squared error as a measure of the accuracy of
the estimates, defining it as:

$$\text{MSE} = \frac{1}{n}\sum\limits_{i = 1}^{n}\left( \theta_{\text{estimated}} - \theta_{\text{generative}} \right)^{2}$$

Finally, we compute the coverage rate for each parameter. For this, we
make use of the estimated value of the standard error for a parameter to
construct the 95%CI around the estimated value of the parameter under
the assumption of normality, specifically (NOTE: THE HIGHER SE, THE MORE
LIKELY TO COVER. MAYBE WE NEED TO LOOK AT SE ITSELF AS WELL?):

$$95\% CI = \left\lbrack \theta_{\text{estimated}} - 1.96 \times \text{SE},\theta_{\text{estimated}} + 1.96 \times \text{SE} \right\rbrack$$
where SE denotes the standard error and 1.96 represents the critical
values of the normal distribution. Coverage is then indicated by
checking whether $\theta_{\text{generative}}$ lies inside of this CI or
not. Aggregating across different parameter sets, we then get to a
coverage percentage, which is of interest here.

#### Reliability

First, we compute the intra-class correlation coefficient ICC(A, 1),
checking how well the values of the parameters match up across different
repetitions of the same strings. This serves as a measure of test-retest
reliability. In our study, it is defined as:

$$\text{ICC(A, 1)} = \frac{\sigma_{\text{participant}}^{2}}{\sigma_{\text{total}}^{2}}$$
where $\sigma_{\text{participant}}^{2}$ is the variance in the parameter
that can be attributed to the participants (i.e., individual
differences) while $\sigma_{\text{total}}^{2}$ is the total observed
variance in the parameter.

Second, we compute the coefficient of variation, which relates the
observed variation in the parameter’s value to the value of that
parameter. In symbols:

$$\text{CV} = \frac{\sigma}{|\mu|}$$ where $\sigma$ and $\mu$ are the
standard deviation and mean of the estimated parameter respectively.

Finally, we compute the signal-to-noise ratio, which is defined as:

$$\text{SNR} = \frac{E\left\lbrack S^{2} \right\rbrack}{E\left\lbrack N^{2} \right\rbrack}$$
where $S$ and $N$ represent the signal and the noise respectively. In
our case, the two components can be computed as:

$$\begin{array}{l}
{E\left\lbrack S^{2} \right\rbrack = \frac{1}{n}\sum\limits_{i = 1}^{n}\theta_{\text{generative}}^{2}} \\
{E\left\lbrack N^{2} \right\rbrack = \frac{1}{n}\sum\limits_{i = 1}^{n}\left( \theta_{\text{generative}} - \theta_{\text{estimated}} \right)^{2}}
\end{array}$$ where $\theta$ represents a parameter of the models.

## References

Vanhasbroeck, N., Vanbelle, S., Moors, A., Vanpaemel, W., & Tuerlinckx,
F. (2024). Chasing consistency: On the measurement error in
self-reported affect in experiments. *Behavior Research Methods, 56*(4),
3009-3022. doi:
[10.3758/s13428-023-02290-3](https://www.doi.org/10.3758/s13428-023-02290-3)

Yu, K., Lin, T.-Y., Zaman, J., Tuerlinckx, F., & Vanhasbroeck, N.
(2025). Consistency of perceptual response variability in size
estimation and reproduction tasks. *Behavior Research Methods, 57*,
Article 127. doi:
[10.3758/s13428-025-02650-1](https://www.doi.org/10.3758/s13428-025-02650-1)
